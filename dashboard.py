# -*- coding: utf-8 -*-
"""
RUBI-like CRM Dashboard (Streamlit, no-Excel build)
- –ü—É–ª—å—Å –≤–æ—Ä–æ–Ω–∫–∏, –∞—É–¥–∏—Ç, –∫–∞—Ä—Ç–æ—á–∫–∏ —Å–¥–µ–ª–æ–∫, –∑–µ–ª—ë–Ω–∞—è/–∫—Ä–∞—Å–Ω–∞—è –∑–æ–Ω—ã –ø–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º
- –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö: Bitrix24 (webhook) –∏–ª–∏ –æ—Ñ–ª–∞–π–Ω-—Ç–∞–±–ª–∏—Ü–∞ (CSV/XLSX)
- –≠–∫—Å–ø–æ—Ä—Ç: ZIP —Å CSV-—Ñ–∞–π–ª–∞–º–∏ (–±–µ–∑ Excel-–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)
"""

import os
import json
import time
import hashlib
from datetime import datetime, timedelta
from io import BytesIO
import zipfile

import numpy as np
import pandas as pd
import streamlit as st

# –ì—Ä–∞—Ñ–∏–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ plotly –Ω–µ—Ç ‚Äî UI —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –Ω–∏—Ö)
try:
    import plotly.express as px
except Exception:
    px = None

# =========================
# –ë–ê–ó–û–í–´–ï –ù–ê–°–¢–†–û–ô–ö–ò UI
# =========================
st.set_page_config(page_title="RUBI-like CRM –ê–Ω–∞–ª–∏—Ç–∏–∫–∞", page_icon="üìà", layout="wide")

CUSTOM_CSS = """
<style>
:root { --rubi-accent:#6C5CE7; --rubi-red:#ff4d4f; --rubi-green:#22c55e; --rubi-yellow:#f59e0b; }
.block-container { padding-top: 1.0rem; padding-bottom: 1.2rem; }
.rubi-card { border-radius:18px; padding:18px 18px 12px; background:#111418; border:1px solid #222; box-shadow:0 4px 18px rgba(0,0,0,.25); }
.rubi-title { font-weight:700; font-size:18px; margin-bottom:6px; }
.rubi-chip { display:inline-flex; align-items:center; gap:6px; padding:4px 10px; border-radius:999px; border:1px solid #2a2f36; background:#0e1216; font-size:12px; margin-right:6px; margin-bottom:6px;}
.rubi-good { color: var(--rubi-green) !important; }
.rubi-bad  { color: var(--rubi-red) !important; }
.small { opacity:.8; font-size:12px; }
hr { border: 0; border-top:1px solid #222; margin: 10px 0 6px }
div[data-testid="stMetricValue"] { font-size:22px !important; }
</style>
"""
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

# =========================
# –ü–†–û–°–¢–ê–Ø –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø
# –ª–æ–≥–∏–Ω: admin
# –ø–∞—Ä–æ–ª—å: 123  (–º–æ–∂–µ—à—å –∑–∞–º–µ–Ω–∏—Ç—å —Ö—ç—à –Ω–∏–∂–µ)
# =========================
def check_password():
    def password_entered():
        ok_user = st.session_state.get("username") in {"admin"}
        # sha256("123")
        target_hash = "a665a45920422f9d417e4867efdc4fb8a04a1f3fff1fa07e998e86f7f7a27ae3"
        ok_pass = hashlib.sha256(st.session_state.get("password","").encode()).hexdigest() == target_hash
        st.session_state["password_correct"] = bool(ok_user and ok_pass)
        st.session_state.pop("password", None)

    if st.secrets.get("DISABLE_AUTH", False):
        st.session_state["password_correct"] = True

    if "password_correct" not in st.session_state or not st.session_state["password_correct"]:
        st.markdown("### üîê –í—Ö–æ–¥ –≤ —Å–∏—Å—Ç–µ–º—É")
        st.text_input("–õ–æ–≥–∏–Ω", key="username")
        st.text_input("–ü–∞—Ä–æ–ª—å", type="password", key="password", on_change=password_entered)
        st.stop()

check_password()
with st.sidebar:
    if st.button("–í—ã–π—Ç–∏"):
        st.session_state["password_correct"] = False
        st.rerun()

# =========================
# –°–ï–ö–†–ï–¢–´ / –ü–ï–†–ï–ú–ï–ù–ù–´–ï
# =========================
def get_secret(name, default=None):
    if name in st.secrets:
        return st.secrets[name]
    return os.getenv(name, default)

BITRIX24_WEBHOOK = (get_secret("BITRIX24_WEBHOOK", "") or "").strip()
PERPLEXITY_API_KEY = (get_secret("PERPLEXITY_API_KEY", "") or "").strip()
PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions"

# =========================
# BITRIX24 HELPERS (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
# =========================
def _bx_get(method, params=None, pause=0.4):
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π GET –∫ Bitrix24 —Å –∞–≤—Ç–æ-–ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π."""
    url = BITRIX24_WEBHOOK.rstrip("/") + f"/{method}.json"
    out, start = [], 0
    params = dict(params or {})
    while True:
        params["start"] = start
        import requests  # –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç, —á—Ç–æ–±—ã –æ—Ñ–ª–∞–π–Ω-—Ä–µ–∂–∏–º –Ω–µ —Ç—Ä–µ–±–æ–≤–∞–ª requests
        r = requests.get(url, params=params, timeout=30)
        data = r.json()
        res = data.get("result")
        if isinstance(res, dict) and "items" in res:
            batch = res.get("items", [])
        else:
            batch = res or []
        if not batch:
            break
        out.extend(batch)
        if len(batch) < 50:
            break
        start += 50
        time.sleep(pause)
    return out

@st.cache_data(show_spinner=False, ttl=300)
def bx_get_deals(date_from=None, date_to=None, limit=1000):
    params = {"select[]":[
        "ID","TITLE","STAGE_ID","OPPORTUNITY","ASSIGNED_BY_ID",
        "COMPANY_ID","CONTACT_ID","PROBABILITY",
        "DATE_CREATE","DATE_MODIFY","LAST_ACTIVITY_TIME"
    ]}
    if date_from: params["filter[>=DATE_CREATE]"] = date_from
    if date_to:   params["filter[<=DATE_CREATE]"] = date_to
    deals = _bx_get("crm.deal.list", params)
    return deals[:limit]

@st.cache_data(show_spinner=False, ttl=300)
def bx_get_users():
    users = _bx_get("user.get", {})
    return {int(u["ID"]): (u.get("NAME","")+ " " + u.get("LAST_NAME","")).strip() or u.get("LOGIN", "") for u in users}

@st.cache_data(show_spinner=False, ttl=300)
def bx_get_open_activities_for_deal_ids(deal_ids):
    """–û—Ç–∫—Ä—ã—Ç—ã–µ –∞–∫—Ç–∏–≤–∏—Ç–∏ –ø–æ —Å–¥–µ–ª–∫–∞–º (–µ—Å—Ç—å –∑–∞–¥–∞—á–∏ ‚Üí –Ω–µ '–±–µ–∑ –∑–∞–¥–∞—á')."""
    out = {}
    if not deal_ids:
        return out
    for chunk in np.array_split(list(map(int, deal_ids)), max(1, len(deal_ids)//40 + 1)):
        params = {
            "filter[OWNER_TYPE_ID]": 2,  # 2 = Deal
            "filter[OWNER_ID]": ",".join(map(str, chunk)),
            "filter[COMPLETED]": "N"
        }
        acts = _bx_get("crm.activity.list", params)
        for a in acts:
            k = int(a["OWNER_ID"])
            out.setdefault(k, []).append(a)
    return out

# =========================
# –û–ë–©–ò–ï –§–£–ù–ö–¶–ò–ò
# =========================
def to_dt(x):
    try:
        return pd.to_datetime(x)
    except Exception:
        return pd.NaT

def compute_health_scores(df, open_tasks_map, stuck_days=5):
    """–°—á–∏—Ç–∞–µ—Ç –∑–¥–æ—Ä–æ–≤—å–µ/–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª/—Ñ–ª–∞–≥–∏ –Ω–∞ –∫–∞–∂–¥—É—é —Å–¥–µ–ª–∫—É."""
    now = pd.Timestamp.utcnow()
    rows = []
    for _, r in df.iterrows():
        last = to_dt(r.get("LAST_ACTIVITY_TIME")) or to_dt(r.get("DATE_MODIFY")) or to_dt(r.get("DATE_CREATE"))
        days_in_work = max(0, (now - to_dt(r.get("DATE_CREATE"))).days if pd.notna(to_dt(r.get("DATE_CREATE"))) else 0)
        days_no_activity = (now - (last if pd.notna(last) else now)).days
        has_task = len(open_tasks_map.get(int(r["ID"]), [])) > 0

        flags = {
            "no_company": int(r.get("COMPANY_ID") or 0) == 0,
            "no_contact": int(r.get("CONTACT_ID") or 0) == 0,
            "no_tasks": not has_task,
            "stuck": days_no_activity >= stuck_days,
            "lost": str(r.get("STAGE_ID","")).upper().find("LOSE") >= 0
        }

        score = 100
        if flags["no_company"]: score -= 10
        if flags["no_contact"]: score -= 10
        if flags["no_tasks"]:   score -= 25
        if flags["stuck"]:      score -= 25
        if flags["lost"]:       score = min(score, 15)

        opp = float(r.get("OPPORTUNITY") or 0.0)
        prob = float(r.get("PROBABILITY") or 0.0)
        potential = min(100, int((opp > 0) * (30 + min(70, np.log10(max(1, opp))/5 * 70)) * (0.4 + prob/100*0.6)))

        rows.append({
            "ID": int(r["ID"]),
            "TITLE": r.get("TITLE",""),
            "ASSIGNED_BY_ID": int(r.get("ASSIGNED_BY_ID") or 0),
            "STAGE_ID": r.get("STAGE_ID",""),
            "OPPORTUNITY": opp,
            "PROBABILITY": prob,
            "DATE_CREATE": to_dt(r.get("DATE_CREATE")),
            "DATE_MODIFY": to_dt(r.get("DATE_MODIFY")),
            "LAST_ACTIVITY_TIME": last,
            "days_in_work": days_in_work,
            "days_no_activity": days_no_activity,
            "health": max(0, min(100, int(score))),
            "potential": max(0, min(100, int(potential))),
            "flag_no_company": flags["no_company"],
            "flag_no_contact": flags["no_contact"],
            "flag_no_tasks": flags["no_tasks"],
            "flag_stuck": flags["stuck"],
            "flag_lost": flags["lost"],
        })
    return pd.DataFrame(rows)

def split_green_red(df_scores):
    grp = df_scores.groupby("ASSIGNED_BY_ID").agg(
        deals=("ID","count"),
        health_avg=("health","mean"),
        potential_sum=("potential","sum"),
        opp_sum=("OPPORTUNITY","sum"),
        no_tasks=("flag_no_tasks","sum"),
        stuck=("flag_stuck","sum"),
        lost=("flag_lost","sum"),
    ).reset_index()
    grp["zone"] = np.where((grp["health_avg"]>=70) & (grp["no_tasks"]<=2) & (grp["stuck"]<=2), "green", "red")
    return grp

def ai_summarize(company_name, df_summary, df_managers, api_key, api_url):
    """–ö–æ—Ä–æ—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ + –ø–ª–∞–Ω (Perplexity). –ë–µ–∑ –∫–ª—é—á–∞ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç stub."""
    if not api_key:
        return "AI-—Ä–µ–∑—é–º–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ (–Ω–µ—Ç API-–∫–ª—é—á–∞).", []
    try:
        import requests
        sample = df_summary.sort_values("health").head(4)[[
            "ID","TITLE","health","potential","OPPORTUNITY","days_in_work",
            "flag_no_tasks","flag_stuck","flag_no_company","flag_no_contact","flag_lost"
        ]].to_dict(orient="records")
        payload = {
            "model": "sonar-pro",
            "messages": [
                {"role":"system","content":"–û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON —Å –∫–ª—é—á–∞–º–∏: summary (string), actions (string[])."},
                {"role":"user","content": json.dumps({
                    "company": company_name,
                    "kpi_summary": df_managers.describe(include="all").to_dict(),
                    "sample_deals": sample
                }, ensure_ascii=False)}
            ],
            "temperature": 0.1,
            "max_tokens": 800
        }
        r = requests.post(api_url, headers={"Authorization":f"Bearer {api_key}"}, json=payload, timeout=60)
        txt = r.json().get("choices",[{}])[0].get("message",{}).get("content","")
        i,j = txt.find("{"), txt.rfind("}")+1
        data = json.loads(txt[i:j]) if i>=0 and j>i else {}
        return data.get("summary","–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å –æ—Ç–≤–µ—Ç."), data.get("actions",[])
    except Exception:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å AI-—Ä–µ–∑—é–º–µ.", []

# =========================
# –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨ / –§–ò–õ–¨–¢–†–´
# =========================
st.sidebar.title("–§–∏–ª—å—Ç—Ä—ã")
company_alias = st.sidebar.text_input("–ö–æ–º–ø–∞–Ω–∏—è (–≤ —à–∞–ø–∫–µ –æ—Ç—á—ë—Ç–∞)", "–û–û–û ¬´–§–æ–∫—É—Å¬ª")
date_from = st.sidebar.date_input("–° –∫–∞–∫–æ–π –¥–∞—Ç—ã", datetime.now().date() - timedelta(days=30))
date_to   = st.sidebar.date_input("–ü–æ –∫–∞–∫—É—é –¥–∞—Ç—É", datetime.now().date())
stuck_days = st.sidebar.slider("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ ‚â• (–¥–Ω–µ–π)", 2, 21, 5)
limit = st.sidebar.slider("–õ–∏–º–∏—Ç —Å–¥–µ–ª–æ–∫ (API)", 50, 3000, 600, step=50)

# –û—Ñ–ª–∞–π–Ω-—Ñ–∞–π–ª (–µ—Å–ª–∏ –Ω–µ—Ç –≤–µ–±—Ö—É–∫–∞)
uploaded_offline = None
if not BITRIX24_WEBHOOK:
    st.sidebar.warning("BITRIX24_WEBHOOK –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –¥–æ—Å—Ç—É–ø–µ–Ω –æ—Ñ–ª–∞–π–Ω-—Ä–µ–∂–∏–º (–∑–∞–≥—Ä—É–∑–∏—Ç–µ CSV/XLSX).")
    uploaded_offline = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å CSV/XLSX —Å–æ —Å–¥–µ–ª–∫–∞–º–∏", type=["csv","xlsx"])

# =========================
# –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•
# =========================
with st.spinner("–ì–æ—Ç–æ–≤–ª—é –¥–∞–Ω–Ω—ã–µ‚Ä¶"):
    if BITRIX24_WEBHOOK:
        deals_raw = bx_get_deals(str(date_from), str(date_to), limit=limit)
        if not deals_raw:
            st.error("–ó–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ —Å–¥–µ–ª–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (Bitrix24).")
            st.stop()
        df_raw = pd.DataFrame(deals_raw)
        df_raw["OPPORTUNITY"] = pd.to_numeric(df_raw.get("OPPORTUNITY"), errors="coerce").fillna(0.0)
        users_map = bx_get_users()
        open_tasks_map = bx_get_open_activities_for_deal_ids(df_raw["ID"].tolist())
    else:
        if not uploaded_offline:
            st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV/XLSX —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –º–∏–Ω–∏–º—É–º: ID, TITLE, STAGE_ID, OPPORTUNITY, ASSIGNED_BY_ID, "
                    "COMPANY_ID, CONTACT_ID, PROBABILITY, DATE_CREATE, DATE_MODIFY, LAST_ACTIVITY_TIME.")
            st.stop()
        # —á–∏—Ç–∞–µ–º –æ—Ñ–ª–∞–π–Ω-—Ç–∞–±–ª–∏—Ü—É
        if uploaded_offline.name.lower().endswith(".csv"):
            df_raw = pd.read_csv(uploaded_offline)
        else:
            df_raw = pd.read_excel(uploaded_offline)

        df_raw.columns = [c.strip() for c in df_raw.columns]
        must = ["ID","TITLE","STAGE_ID","OPPORTUNITY","ASSIGNED_BY_ID",
                "COMPANY_ID","CONTACT_ID","PROBABILITY","DATE_CREATE","DATE_MODIFY","LAST_ACTIVITY_TIME"]
        missing = [c for c in must if c not in df_raw.columns]
        if missing:
            st.error(f"–ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –∫–æ–ª–æ–Ω–æ–∫: {missing}")
            st.stop()
        df_raw["OPPORTUNITY"] = pd.to_numeric(df_raw["OPPORTUNITY"], errors="coerce").fillna(0.0)
        users_map = {int(i): str(i) for i in pd.to_numeric(df_raw["ASSIGNED_BY_ID"], errors="coerce").fillna(0).astype(int).unique()}
        if "manager" in df_raw.columns:
            for aid, name in df_raw[["ASSIGNED_BY_ID","manager"]].dropna().values:
                try:
                    users_map[int(aid)] = str(name)
                except Exception:
                    pass
        open_tasks_map = {}  # –≤ –æ—Ñ–ª–∞–π–Ω–µ —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –∑–∞–¥–∞—á –Ω–µ—Ç (–∏–ª–∏ –¥–æ–±–∞–≤—å –∫–æ–ª–æ–Ω–∫—É –¥–ª—è —è–≤–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞)

    # –†–∞—Å—á—ë—Ç—ã
    df_scores = compute_health_scores(df_raw, open_tasks_map, stuck_days=stuck_days)
    df_scores["manager"] = df_scores["ASSIGNED_BY_ID"].map(users_map).fillna("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
    mgr = split_green_red(df_scores)

# =========================
# –í–ï–†–• –®–ê–ü–ö–ò
# =========================
st.title("RUBI-style –ö–æ–Ω—Ç—Ä–æ–ª—å –æ—Ç–¥–µ–ª–∞ –ø—Ä–æ–¥–∞–∂")
st.caption("–ê–≤—Ç–æ–∞—É–¥–∏—Ç –≤–æ—Ä–æ–Ω–∫–∏ ‚Ä¢ –ü—É–ª—å—Å —Å–¥–µ–ª–æ–∫ ‚Ä¢ –ó–æ–Ω—ã –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ ‚Ä¢ –ö–∞—Ä—Ç–æ—á–∫–∏ ‚Ä¢ –≠–∫—Å–ø–æ—Ä—Ç CSV")

# –¢–æ–ø-–º–µ—Ç—Ä–∏–∫–∏
c1,c2,c3,c4,c5 = st.columns(5, gap="small")
with c1: st.metric("–í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫", int(df_scores.shape[0]))
with c2: st.metric("–û–±—ä—ë–º, ‚ÇΩ", f"{int(df_scores['OPPORTUNITY'].sum()):,}".replace(","," "))
with c3: st.metric("–°—Ä–µ–¥–Ω–∏–π —á–µ–∫, ‚ÇΩ", f"{int(df_scores['OPPORTUNITY'].replace(0,np.nan).mean() or 0):,}".replace(","," "))
with c4: st.metric("–°—Ä–µ–¥–Ω. –∑–¥–æ—Ä–æ–≤—å–µ", f"{df_scores['health'].mean():.0f}%")
with c5: st.metric("–°—É–º–º–∞—Ä–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª", int(df_scores["potential"].sum()))

# =========================
# –í–ö–õ–ê–î–ö–ò
# =========================
tab_pulse, tab_audit, tab_managers, tab_cards, tab_export = st.tabs([
    "‚õµ –ü—É–ª—å—Å —Å–¥–µ–ª–æ–∫", "üöÅ –ê—É–¥–∏—Ç –≤–æ—Ä–æ–Ω–∫–∏", "üöÄ –ú–µ–Ω–µ–¥–∂–µ—Ä—ã", "üóÇ –ö–∞—Ä—Ç–æ—á–∫–∏", "‚¨áÔ∏è –≠–∫—Å–ø–æ—Ä—Ç (CSV)"
])

# --- –ü–£–õ–¨–°
with tab_pulse:
    if px is None:
        st.warning("Plotly –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî –≥—Ä–∞—Ñ–∏–∫–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã.")
    else:
        a,b = st.columns([3,2], gap="large")
        with a:
            st.subheader("–î–∏–Ω–∞–º–∏–∫–∞ –ø–æ —ç—Ç–∞–ø–∞–º")
            stage_df = df_scores.groupby("STAGE_ID").agg(–°—É–º–º–∞=("OPPORTUNITY","sum"), –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ=("ID","count")).reset_index()
            fig = px.bar(stage_df, x="STAGE_ID", y="–°—É–º–º–∞", text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
            st.plotly_chart(fig, use_container_width=True)
        with b:
            st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–¥–æ—Ä–æ–≤—å—è")
            fig2 = px.histogram(df_scores, x="health", nbins=20)
            st.plotly_chart(fig2, use_container_width=True)

    st.subheader("–õ–µ–Ω—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π (–ø–æ—Å–ª–µ–¥–Ω–∏–µ)")
    st.dataframe(
        df_scores.sort_values("DATE_MODIFY", ascending=False)[
            ["ID","TITLE","manager","STAGE_ID","OPPORTUNITY","health","potential","DATE_MODIFY"]
        ].head(200),
        height=360
    )

# --- –ê–£–î–ò–¢
with tab_audit:
    st.subheader("–ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –∑–æ–Ω—ã")
    kpis = {
        "–°–¥–µ–ª–æ–∫ –±–µ–∑ –∑–∞–¥–∞—á": int((~df_scores["ID"].isin(open_tasks_map.keys())).sum()),
        "–°–¥–µ–ª–æ–∫ –±–µ–∑ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤": int(df_scores["flag_no_contact"].sum()),
        "–°–¥–µ–ª–æ–∫ –±–µ–∑ –∫–æ–º–ø–∞–Ω–∏–π": int(df_scores["flag_no_company"].sum()),
        "–ó–∞—Å—Ç—Ä—è–≤—à–∏–µ —Å–¥–µ–ª–∫–∏": int(df_scores["flag_stuck"].sum()),
        "–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ —Å–¥–µ–ª–∫–∏": int(df_scores["flag_lost"].sum()),
    }
    a,b,c,d,e = st.columns(5)
    a.metric("–ë–µ–∑ –∑–∞–¥–∞—á", kpis["–°–¥–µ–ª–æ–∫ –±–µ–∑ –∑–∞–¥–∞—á"])
    b.metric("–ë–µ–∑ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤", kpis["–°–¥–µ–ª–æ–∫ –±–µ–∑ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤"])
    c.metric("–ë–µ–∑ –∫–æ–º–ø–∞–Ω–∏–π", kpis["–°–¥–µ–ª–æ–∫ –±–µ–∑ –∫–æ–º–ø–∞–Ω–∏–π"])
    d.metric("–ó–∞—Å—Ç—Ä—è–ª–∏", kpis["–ó–∞—Å—Ç—Ä—è–≤—à–∏–µ —Å–¥–µ–ª–∫–∏"])
    e.metric("–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ", kpis["–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ —Å–¥–µ–ª–∫–∏"])

    st.markdown("##### –°–ø–∏—Å–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
    cols = st.columns(5, gap="small")
    lists = [
        ("–ë–µ–∑ –∑–∞–¥–∞—á", ~df_scores["ID"].isin(open_tasks_map.keys())),
        ("–ë–µ–∑ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤", df_scores["flag_no_contact"]),
        ("–ë–µ–∑ –∫–æ–º–ø–∞–Ω–∏–π", df_scores["flag_no_company"]),
        ("–ó–∞—Å—Ç—Ä—è–ª–∏", df_scores["flag_stuck"]),
        ("–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ", df_scores["flag_lost"]),
    ]
    for (title, mask), holder in zip(lists, cols):
        with holder:
            st.markdown(f'<div class="rubi-card"><div class="rubi-title">{title}</div>', unsafe_allow_html=True)
            st.dataframe(
                df_scores[mask][["ID","TITLE","manager","STAGE_ID","OPPORTUNITY","health","days_no_activity"]].head(80),
                height=260
            )
            st.markdown("</div>", unsafe_allow_html=True)

# --- –ú–ï–ù–ï–î–ñ–ï–†–´
with tab_managers:
    st.subheader("–ó–µ–ª—ë–Ω–∞—è / –ö—Ä–∞—Å–Ω–∞—è –∑–æ–Ω—ã –ø–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º")
    mgr = mgr.copy()
    mgr["manager"] = mgr["ASSIGNED_BY_ID"].map(users_map).fillna("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")

    left, right = st.columns([1.5,1], gap="large")

    with left:
        if px is None:
            st.info("Plotly –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî –¥–∏–∞–≥—Ä–∞–º–º–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞.")
        else:
            fig = px.scatter(
                mgr, x="health_avg", y="no_tasks", size="opp_sum", color="zone",
                hover_data=["manager","deals","stuck","lost","potential_sum"],
                labels={"health_avg":"–°—Ä–µ–¥–Ω. –∑–¥–æ—Ä–æ–≤—å–µ","no_tasks":"–ë–µ–∑ –∑–∞–¥–∞—á (—à—Ç)"}
            )
            st.plotly_chart(fig, use_container_width=True)

        st.markdown("**–¢–∞–±–ª–∏—Ü–∞ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤**")
        st.dataframe(
            mgr[["manager","deals","opp_sum","health_avg","no_tasks","stuck","lost","zone"]]
            .sort_values(["zone","health_avg"], ascending=[True,False]),
            height=380
        )

    with right:
        st.markdown("#### –õ–∏–¥–µ—Ä—ã –∏ —Ä–∏—Å–∫–æ–≤—ã–µ")
        agg = df_scores.groupby("manager").agg(
            deals=("ID","count"),
            health_avg=("health","mean"),
            opp=("OPPORTUNITY","sum"),
            stuck=("flag_stuck","sum"),
            no_tasks=("flag_no_tasks","sum"),
            lost=("flag_lost","sum"),
        ).reset_index()

        st.markdown("**–ó–µ–ª—ë–Ω–∞—è –∑–æ–Ω–∞**")
        st.dataframe(agg.query("health_avg>=70").sort_values("health_avg", ascending=False).head(10), height=180)
        st.markdown("**–ö—Ä–∞—Å–Ω–∞—è –∑–æ–Ω–∞**")
        st.dataframe(agg.query("health_avg<70 or no_tasks>2 or stuck>2")
                     .sort_values(["health_avg","no_tasks","stuck"], ascending=[True,False,False]).head(10), height=180)

# --- –ö–ê–†–¢–û–ß–ö–ò
with tab_cards:
    st.subheader("–ö–∞—Ä—Ç–æ—á–∫–∏ —Å –æ—Ü–µ–Ω–∫–æ–π –∏ –ø–ª–∞–Ω–æ–º")
    pick_manager = st.multiselect("–§–∏–ª—å—Ç—Ä –ø–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º", sorted(df_scores["manager"].unique()), default=[])
    pick = df_scores[df_scores["manager"].isin(pick_manager)] if pick_manager else df_scores
    pick = pick.sort_values(["health","potential","OPPORTUNITY"], ascending=[True,False,False]).head(30)

    grid_cols = st.columns(3, gap="medium")
    for i, (_, row) in enumerate(pick.iterrows()):
        with grid_cols[i % 3]:
            status = "rubi-bad" if row["health"] < 60 else ("rubi-good" if row["health"]>=80 else "")
            risks_list = [k.replace("flag_","").replace("_"," ") for k in [
                "flag_no_tasks","flag_no_company","flag_no_contact","flag_stuck"
            ] if row[k]]
            st.markdown(f"""
            <div class="rubi-card">
              <div class="rubi-title">{row['TITLE']}</div>
              <div class="small">ID {row['ID']} ‚Ä¢ {row['manager']}</div>
              <hr/>
              <div class="rubi-chip {status}">–ó–¥–æ—Ä–æ–≤—å–µ: <b>{row['health']}%</b></div>
              <div class="rubi-chip">–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª: <b>{row['potential']}%</b></div>
              <div class="rubi-chip">–°—É–º–º–∞: <b>{int(row['OPPORTUNITY']):,} ‚ÇΩ</b></div>
              <div class="rubi-chip">–î–Ω–µ–π –≤ —Ä–∞–±–æ—Ç–µ: <b>{row['days_in_work']}</b></div>
              <div class="rubi-chip">–ë–µ–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: <b>{row['days_no_activity']} –¥–Ω</b></div>
              <hr/>
              <div class="small">
                ‚ö†Ô∏è –†–∏—Å–∫–∏: {", ".join(risks_list) or "–Ω–µ—Ç"}<br/>
                ‚ùå –ü–æ—Ç–µ—Ä—è–Ω–∞: {"–¥–∞" if row["flag_lost"] else "–Ω–µ—Ç"}<br/>
              </div>
            </div>
            """, unsafe_allow_html=True)

# --- –≠–ö–°–ü–û–†–¢ (CSV –≤ ZIP)
with tab_export:
    st.subheader("–≠–∫—Å–ø–æ—Ä—Ç CSV (ZIP) ‚Äî —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ Excel")

    # 01 ‚Äî –°–≤–æ–¥–∫–∞
    summary_df = pd.DataFrame({
        "–ú–µ—Ç—Ä–∏–∫–∞": ["–í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫","–û–±—ä—ë–º","–°—Ä–µ–¥–Ω. –∑–¥–æ—Ä–æ–≤—å–µ","–ó–∞—Å—Ç—Ä—è–ª–∏","–ë–µ–∑ –∑–∞–¥–∞—á","–ë–µ–∑ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤","–ë–µ–∑ –∫–æ–º–ø–∞–Ω–∏–π","–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ"],
        "–ó–Ω–∞—á–µ–Ω–∏–µ": [
            df_scores.shape[0],
            int(df_scores["OPPORTUNITY"].sum()),
            f"{df_scores['health'].mean():.0f}%",
            int(df_scores["flag_stuck"].sum()),
            int((~df_scores['ID'].isin(open_tasks_map.keys())).sum()),
            int(df_scores["flag_no_contact"].sum()),
            int(df_scores["flag_no_company"].sum()),
            int(df_scores["flag_lost"].sum()),
        ]
    })

    # 02 ‚Äî –ú–µ–Ω–µ–¥–∂–µ—Ä—ã
    mgr_out = split_green_red(df_scores)
    mgr_out["manager"] = mgr_out["ASSIGNED_BY_ID"].map(users_map).fillna("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
    mgr_out = mgr_out[["manager","deals","opp_sum","health_avg","no_tasks","stuck","lost","zone"]]

    # 03 ‚Äî –°–¥–µ–ª–∫–∏
    deal_cols = ["ID","TITLE","manager","STAGE_ID","OPPORTUNITY","PROBABILITY","health","potential",
                 "days_in_work","days_no_activity","flag_no_tasks","flag_no_contact","flag_no_company",
                 "flag_stuck","flag_lost","DATE_CREATE","DATE_MODIFY","LAST_ACTIVITY_TIME"]
    deals_out = df_scores[deal_cols].copy()

    def pack_zip_csv():
        mem = BytesIO()
        with zipfile.ZipFile(mem, mode="w", compression=zipfile.ZIP_DEFLATED) as zf:
            zf.writestr("01_summary.csv", summary_df.to_csv(index=False, encoding="utf-8-sig"))
            zf.writestr("02_managers.csv", mgr_out.to_csv(index=False, encoding="utf-8-sig"))
            zf.writestr("03_deals.csv", deals_out.to_csv(index=False, encoding="utf-8-sig"))
        mem.seek(0)
        return mem.getvalue()

    zip_bytes = pack_zip_csv()
    st.download_button(
        "–°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç (CSV.zip)",
        data=zip_bytes,
        file_name="rubi_like_report_csv.zip",
        mime="application/zip"
    )

# =========================
# AI-–ö–†–ê–¢–ö–û–ï –†–ï–ó–Æ–ú–ï
# =========================
st.markdown("### üîÆ AI-—Ä–µ–∑—é–º–µ –∏ –ø–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π")
if st.button("–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∫—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä"):
    with st.spinner("–§–æ—Ä–º–∏—Ä—É—é AI-–æ–±–∑–æ—Ä‚Ä¶"):
        text, actions = ai_summarize(company_alias, df_scores, mgr, PERPLEXITY_API_KEY, PERPLEXITY_API_URL)
    st.info(text or "‚Äî")
    if actions:
        st.markdown("**–®–∞–≥–∏:**")
        for a in actions:
            st.write(f"‚Ä¢ {a}")
    else:
        st.caption("–ù–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π / –ò–ò –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")

# =========================
# –ü–û–î–í–ê–õ
# =========================
st.caption("RUBI-like Dashboard ‚Ä¢ –∞–≤—Ç–æ–∞—É–¥–∏—Ç, –ø—É–ª—å—Å, –º–µ–Ω–µ–¥–∂–µ—Ä—Å–∫–∏–µ –∑–æ–Ω—ã, –∫–∞—Ä—Ç–æ—á–∫–∏, —ç–∫—Å–ø–æ—Ä—Ç CSV. v1.2 (no-Excel)")
