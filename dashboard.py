# -*- coding: utf-8 -*-
"""
–ë–£–†–ú–ê–® ¬∑ CRM –î—ç—à–±–æ—Ä–¥ v4.2
–° AI-–∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π, –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø—Ä–æ–±–ª–µ–º –∏ –≥–æ–¥–æ–≤—ã–º –ø–ª–∞–Ω–æ–º
"""
import os, time, math, json
from datetime import datetime, timedelta
import numpy as np
import pandas as pd
import streamlit as st
import requests

try:
    import plotly.express as px
    import plotly.graph_objects as go
except:
    px = go = None

# ============ CONFIG ============
st.set_page_config(page_title="–ë–£–†–ú–ê–® ¬∑ CRM", page_icon="üüß", layout="wide")

def check_password():
    def password_entered():
        st.session_state["password_correct"] = (
            st.session_state.get("username") == "admin" and
            st.session_state.get("password") == "admin123"
        )
        st.session_state.pop("password", None)
    if st.secrets.get("DISABLE_AUTH", False):
        st.session_state["password_correct"] = True
    if not st.session_state.get("password_correct", False):
        st.markdown("### üîê –í—Ö–æ–¥ ‚Äî –ë–£–†–ú–ê–®")
        st.text_input("–õ–æ–≥–∏–Ω", key="username")
        st.text_input("–ü–∞—Ä–æ–ª—å", type="password", key="password", on_change=password_entered)
        st.stop()

check_password()
with st.sidebar:
    if st.button("–í—ã–π—Ç–∏"):
        st.session_state["password_correct"] = False
        st.rerun()

def get_secret(name, default=None):
    return st.secrets.get(name) or os.getenv(name, default) or default

BITRIX24_WEBHOOK = (get_secret("BITRIX24_WEBHOOK", "") or "").strip()
PERPLEXITY_API_KEY = (get_secret("PERPLEXITY_API_KEY", "") or "").strip()

# ============ BITRIX HELPERS ============
def _bx_get(method, params=None, pause=0.4):
    url = BITRIX24_WEBHOOK.rstrip("/") + f"/{method}.json"
    out, start = [], 0
    params = dict(params or {})
    while True:
        params["start"] = start
        r = requests.get(url, params=params, timeout=30)
        data = r.json()
        res = data.get("result")
        batch = (res.get("items", []) if isinstance(res, dict) and "items" in res else res) or []
        if not batch: break
        out.extend(batch)
        if len(batch) < 50: break
        start += 50
        time.sleep(pause)
    return out

@st.cache_data(ttl=300)
def bx_get_deals(date_from=None, date_to=None, limit=1000):
    params = {"select[]":[
        "ID","TITLE","STAGE_ID","OPPORTUNITY","ASSIGNED_BY_ID","COMPANY_ID","CONTACT_ID",
        "PROBABILITY","DATE_CREATE","DATE_MODIFY","LAST_ACTIVITY_TIME","CATEGORY_ID","BEGINDATE"
    ]}
    if date_from: params["filter[>=DATE_CREATE]"] = date_from
    if date_to: params["filter[<=DATE_CREATE]"] = date_to
    deals = _bx_get("crm.deal.list", params)
    return deals[:limit]

@st.cache_data(ttl=300)
def bx_get_users_full():
    users = _bx_get("user.get", {})
    out = {}
    for u in users:
        depts = u.get("UF_DEPARTMENT") or []
        if isinstance(depts, str): depts = [int(x) for x in depts.split(",") if x]
        out[int(u["ID"])] = {
            "name": ((u.get("NAME","")+u.get("LAST_NAME","")).strip() or u.get("LOGIN","")).strip(),
            "depts": list(map(int, depts)) if depts else [],
            "active": (u.get("ACTIVE","Y")=="Y")
        }
    return out

@st.cache_data(ttl=300)
def bx_get_open_activities_for_deal_ids(deal_ids):
    out = {}
    if not deal_ids: return out
    for chunk in np.array_split(list(map(int, deal_ids)), max(1, len(deal_ids)//40 + 1)):
        params = {"filter[OWNER_TYPE_ID]":2,"filter[OWNER_ID]":",".join(map(str,chunk)),"filter[COMPLETED]":"N"}
        acts = _bx_get("crm.activity.list", params)
        for a in acts:
            out.setdefault(int(a["OWNER_ID"]), []).append(a)
    return out

@st.cache_data(ttl=600)
def bx_get_stage_map(stage_ids):
    sort_map, name_map = {}, {}
    if not BITRIX24_WEBHOOK or not stage_ids: return sort_map, name_map
    cats = set()
    for sid in stage_ids:
        if isinstance(sid, str) and sid.startswith("C"):
            try: cats.add(int(sid.split(":")[0][1:]))
            except: pass
    try:
        base = _bx_get("crm.status.list", {"filter[ENTITY_ID]":"DEAL_STAGE"})
        for s in base:
            sort_map[s.get("STATUS_ID")] = int(s.get("SORT", 5000))
            name_map[s.get("STATUS_ID")] = s.get("NAME") or s.get("STATUS_ID")
    except: pass
    for cid in cats:
        try:
            resp = _bx_get("crm.status.list", {"filter[ENTITY_ID]": f"DEAL_STAGE_{cid}"})
            for s in resp:
                sort_map[s.get("STATUS_ID")] = int(s.get("SORT", 5000))
                name_map[s.get("STATUS_ID")] = s.get("NAME") or s.get("STATUS_ID")
        except: continue
    return sort_map, name_map

@st.cache_data(ttl=600)
def bx_get_categories():
    try:
        cats = _bx_get("crm.category.list", {})
        return {int(c["ID"]): c.get("NAME","–í–æ—Ä–æ–Ω–∫–∞") for c in cats}
    except:
        return {}

# ============ AI ANALYSIS ============
def ai_analyze_manager(manager_name, deals_summary):
    if not PERPLEXITY_API_KEY:
        return "AI-–∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω."
    prompt = f"""
–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º –∏ CRM-–∞–Ω–∞–ª–∏—Ç–∏–∫–µ. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–∞–±–æ—Ç—É –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º.

–ú–µ–Ω–µ–¥–∂–µ—Ä: {manager_name}
–î–∞–Ω–Ω—ã–µ: {json.dumps(deals_summary, ensure_ascii=False)}

–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ (2-3 –∞–±–∑–∞—Ü–∞):
1. –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∏ —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ
2. –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –∑–æ–Ω—ã –∏ –∑–∞–ø–∞–¥–∞–Ω–∏—è
3. –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π

–ü–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –¥–µ–ª–æ–≤—ã–º —Å—Ç–∏–ª–µ–º.
"""
    data = {
        "model": "sonar-pro",
        "messages": [
            {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ CRM-–∞–Ω–∞–ª–∏—Ç–∏–∫–µ."},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": 800,
        "temperature": 0.3
    }
    try:
        resp = requests.post(
            "https://api.perplexity.ai/chat/completions",
            headers={"Authorization": f"Bearer {PERPLEXITY_API_KEY}"},
            json=data,
            timeout=30
        )
        result = resp.json()
        return result["choices"][0]["message"]["content"]
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ AI-–∞–Ω–∞–ª–∏–∑–∞: {str(e)}"

# ============ UTILS ============
def to_dt(x):
    try:
        ts = pd.to_datetime(x, utc=True, errors="coerce")
        if pd.isna(ts): return pd.NaT
        return ts.tz_convert(None)
    except: return pd.NaT

def days_between(later, earlier):
    a, b = to_dt(later), to_dt(earlier)
    if pd.isna(a) or pd.isna(b): return None
    return max(0, int((a - b) / pd.Timedelta(days=1)))

# ============ SCORING ============
def compute_health_scores(df, open_tasks_map, stuck_days=5):
    now = to_dt(pd.Timestamp.utcnow())
    rows = []
    for _, r in df.iterrows():
        create_dt = to_dt(r.get("DATE_CREATE"))
        last = to_dt(r.get("LAST_ACTIVITY_TIME")) or to_dt(r.get("DATE_MODIFY")) or create_dt
        begin_dt = to_dt(r.get("BEGINDATE")) or create_dt
        d_work = days_between(now, create_dt) or 0
        d_noact = days_between(now, last) or 0
        d_in_stage = days_between(now, begin_dt) or 0
        has_task = len(open_tasks_map.get(int(r["ID"]), [])) > 0
        flags = {
            "no_company": int(r.get("COMPANY_ID") or 0) == 0,
            "no_contact": int(r.get("CONTACT_ID") or 0) == 0,
            "no_tasks": not has_task,
            "stuck": d_noact >= stuck_days,
            "lost": str(r.get("STAGE_ID","")).upper().find("LOSE") >= 0
        }
        score = 100
        if flags["no_company"]: score -= 10
        if flags["no_contact"]: score -= 10
        if flags["no_tasks"]: score -= 25
        if flags["stuck"]: score -= 25
        if flags["lost"]: score = min(score, 15)
        opp = float(r.get("OPPORTUNITY") or 0.0)
        prob = float(r.get("PROBABILITY") or 0.0)
        potential = min(100, int((opp > 0) * (30 + min(70, math.log10(max(1, opp))/5 * 70)) * (0.4 + prob/100 * 0.6)))
        rows.append({
            "ID —Å–¥–µ–ª–∫–∏": int(r["ID"]),
            "–ù–∞–∑–≤–∞–Ω–∏–µ": r.get("TITLE",""),
            "–ú–µ–Ω–µ–¥–∂–µ—Ä ID": int(r.get("ASSIGNED_BY_ID") or 0),
            "–≠—Ç–∞–ø ID": r.get("STAGE_ID",""),
            "–í–æ—Ä–æ–Ω–∫–∞ ID": r.get("CATEGORY_ID"),
            "–°—É–º–º–∞": opp,
            "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å": prob,
            "–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è": create_dt,
            "–î–∞—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è": to_dt(r.get("DATE_MODIFY")),
            "–ü–æ—Å–ª–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å": last,
            "–ù–∞—á–∞–ª–æ —ç—Ç–∞–ø–∞": begin_dt,
            "–î–Ω–µ–π –≤ —Ä–∞–±–æ—Ç–µ": d_work,
            "–î–Ω–µ–π –±–µ–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏": d_noact,
            "–î–Ω–µ–π –Ω–∞ —ç—Ç–∞–ø–µ": d_in_stage,
            "–ó–¥–æ—Ä–æ–≤—å–µ": max(0, min(100, int(score))),
            "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª": max(0, min(100, int(potential))),
            "–ù–µ—Ç –∫–æ–º–ø–∞–Ω–∏–∏": flags["no_company"],
            "–ù–µ—Ç –∫–æ–Ω—Ç–∞–∫—Ç–∞": flags["no_contact"],
            "–ù–µ—Ç –∑–∞–¥–∞—á": flags["no_tasks"],
            "–ó–∞—Å—Ç—Ä—è–ª–∞": flags["stuck"],
            "–ü—Ä–æ–∏–≥—Ä–∞–Ω–∞": flags["lost"],
        })
    return pd.DataFrame(rows)

def focus_scores(df, horizon_days=14, min_prob=50):
    if df.empty:
        return df.assign(–°–∫–æ—Ä_–±—ã—Å—Ç—Ä–æ–π_–ø–æ–±–µ–¥—ã=0.0, ETA_–¥–Ω–µ–π=np.nan, –°–∫–æ—Ä_–æ—Ç–∫–∞–∑–∞=0.0)
    eps = 1e-9
    prob = df["–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å"].clip(0, 100) / 100.0
    health = df["–ó–¥–æ—Ä–æ–≤—å–µ"].clip(0,100) / 100.0
    opp = df["–°—É–º–º–∞"].clip(lower=0)
    opp_norm = np.log1p(opp) / max(np.log1p(opp).max(), eps)
    smin, smax = float(df["–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —ç—Ç–∞–ø–∞"].min()), float(df["–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —ç—Ç–∞–ø–∞"].max())
    if smax - smin < eps:
        stage_closeness = pd.Series(0.5, index=df.index)
    else:
        stage_closeness = (df["–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —ç—Ç–∞–ø–∞"] - smin) / (smax - smin)
    stage_closeness = np.where(df["–≠—Ç–∞–ø ID"].astype(str).str.contains("LOSE", case=False, na=False), 0.0, stage_closeness)
    recency = 1 - (df["–î–Ω–µ–π –±–µ–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"].clip(lower=0) / max(horizon_days, 1)).clip(0,1)
    quick = (0.35*prob + 0.25*health + 0.15*recency + 0.15*stage_closeness + 0.10*opp_norm)
    quick_score = (quick*100).round(1)
    eta = (30*(1-stage_closeness)*(1 - 0.5*health - 0.5*prob)).clip(lower=0)
    eta_days = eta.round(0)
    age_norm = (df["–î–Ω–µ–π –≤ —Ä–∞–±–æ—Ç–µ"]/max(df["–î–Ω–µ–π –≤ —Ä–∞–±–æ—Ç–µ"].max(),1)).clip(0,1)
    noact_norm = (df["–î–Ω–µ–π –±–µ–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"]/max(df["–î–Ω–µ–π –±–µ–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"].max(),1)).clip(0,1)
    drop = (1-prob)*0.4 + (1-health)*0.3 + noact_norm*0.2 + age_norm*0.1
    drop_score = (drop*100).round(1)
    out = df.copy()
    out["–°–∫–æ—Ä –±—ã—Å—Ç—Ä–æ–π –ø–æ–±–µ–¥—ã"] = quick_score
    out["ETA –¥–Ω–µ–π"] = eta_days
    out["–°–∫–æ—Ä –æ—Ç–∫–∞–∑–∞"] = drop_score
    out["–ë—ã—Å—Ç—Ä–∞—è –ø–æ–±–µ–¥–∞?"] = (out["–°–∫–æ—Ä –±—ã—Å—Ç—Ä–æ–π –ø–æ–±–µ–¥—ã"]>=60) & (out["–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å"]>=min_prob) & (~out["–ü—Ä–æ–∏–≥—Ä–∞–Ω–∞"])
    out["–°—Ç–æ–ø-–ª–∏—Å—Ç?"] = (out["–°–∫–æ—Ä –æ—Ç–∫–∞–∑–∞"]>=70) | (out["–ü—Ä–æ–∏–≥—Ä–∞–Ω–∞"]) | ((out["–ó–¥–æ—Ä–æ–≤—å–µ"]<40) & (out["–î–Ω–µ–π –±–µ–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"]>horizon_days))
    return out

def compute_conversion_by_manager_and_funnel(df, sort_map):
    results = []
    for (mgr, cat), g in df.groupby(["–ú–µ–Ω–µ–¥–∂–µ—Ä", "–í–æ—Ä–æ–Ω–∫–∞"], dropna=False):
        stages_sorted = sorted(g["–≠—Ç–∞–ø ID"].unique(), key=lambda s: sort_map.get(str(s), 9999))
        stage_counts = g.groupby("–≠—Ç–∞–ø ID").size()
        total = len(g)
        stage_data = []
        for s in stages_sorted:
            cnt = stage_counts.get(s, 0)
            conv = (cnt / total * 100) if total > 0 else 0
            stage_data.append({"–≠—Ç–∞–ø": s, "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ": cnt, "–ö–æ–Ω–≤–µ—Ä—Å–∏—è %": round(conv, 1)})
        results.append({
            "–ú–µ–Ω–µ–¥–∂–µ—Ä": mgr,
            "–í–æ—Ä–æ–Ω–∫–∞": cat,
            "–í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫": total,
            "–≠—Ç–∞–ø—ã": stage_data
        })
    return pd.DataFrame(results)

# ============ SIDEBAR ============
st.sidebar.title("–§–∏–ª—å—Ç—Ä—ã")
date_from = st.sidebar.date_input("–° –¥–∞—Ç—ã", datetime.now().date() - timedelta(days=30))
date_to   = st.sidebar.date_input("–ü–æ –¥–∞—Ç—É", datetime.now().date())
stuck_days= st.sidebar.slider("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ ‚â• (–¥–Ω–µ–π)", 2, 21, 5)
limit     = st.sidebar.slider("–õ–∏–º–∏—Ç —Å–¥–µ–ª–æ–∫ (API)", 50, 3000, 600, step=50)

st.sidebar.title("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ñ–æ–∫—É—Å–∞ –†–û–ü–∞")
focus_horizon = st.sidebar.slider("–ì–æ—Ä–∏–∑–æ–Ω—Ç —Ñ–æ–∫—É—Å–∞ (–¥–Ω–µ–π)", 7, 45, 14)
focus_min_prob= st.sidebar.slider("–ú–∏–Ω. –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–ª—è —Ñ–æ–∫—É—Å–∞, %", 0, 100, 50)

# ============ LOAD DATA ============
with st.spinner("–ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ‚Ä¶"):
    if not BITRIX24_WEBHOOK:
        st.error("–ó–∞–¥–∞–π—Ç–µ BITRIX24_WEBHOOK –≤ Secrets")
        st.stop()
    deals_raw = bx_get_deals(str(date_from), str(date_to), limit=limit)
    if not deals_raw:
        st.error("–°–¥–µ–ª–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.")
        st.stop()
    df_raw = pd.DataFrame(deals_raw)
    df_raw["OPPORTUNITY"] = pd.to_numeric(df_raw.get("OPPORTUNITY"), errors="coerce").fillna(0.0)
    users_full = bx_get_users_full()
    users_map = {uid: users_full[uid]["name"] for uid in users_full}
    open_tasks_map = bx_get_open_activities_for_deal_ids(df_raw["ID"].tolist())
    categories_map   = bx_get_categories()

df_scores = compute_health_scores(df_raw, open_tasks_map, stuck_days=stuck_days)
stage_ids = df_scores["–≠—Ç–∞–ø ID"].dropna().unique().tolist()
sort_map, name_map = bx_get_stage_map(stage_ids)
FALLBACK_ORDER = ["NEW","NEW_LEAD","PREPARATION","PREPAYMENT_INVOICE","EXECUTING","FINAL_INVOICE","WON","LOSE"]
def fallback_sort(sid):
    sid = str(sid or "")
    sid_short = sid.split(":")[1] if ":" in sid else sid
    return (FALLBACK_ORDER.index(sid_short)*100 if sid_short in FALLBACK_ORDER else 10000 + hash(sid_short)%1000)
df_scores["–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —ç—Ç–∞–ø–∞"] = df_scores["–≠—Ç–∞–ø ID"].map(lambda s: sort_map.get(str(s), fallback_sort(s)))
df_scores["–ù–∞–∑–≤–∞–Ω–∏–µ —ç—Ç–∞–ø–∞"] = df_scores["–≠—Ç–∞–ø ID"].map(lambda s: name_map.get(str(s), str(s)))
df_scores["–ú–µ–Ω–µ–¥–∂–µ—Ä"] = df_scores["–ú–µ–Ω–µ–¥–∂–µ—Ä ID"].map(users_map).fillna("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
df_scores["–í–æ—Ä–æ–Ω–∫–∞"]  = df_scores["–í–æ—Ä–æ–Ω–∫–∞ ID"].map(lambda x: categories_map.get(int(x or 0), "–û—Å–Ω–æ–≤–Ω–∞—è"))
df_scores = focus_scores(df_scores, horizon_days=focus_horizon, min_prob=focus_min_prob)

funnels  = sorted(df_scores["–í–æ—Ä–æ–Ω–∫–∞"].unique())
selected_funnels  = st.sidebar.multiselect("–í–æ—Ä–æ–Ω–∫–∏", funnels, default=funnels)
managers = sorted(df_scores["–ú–µ–Ω–µ–¥–∂–µ—Ä"].unique())
selected_managers = st.sidebar.multiselect("–ú–µ–Ω–µ–¥–∂–µ—Ä—ã", managers, default=managers)

view_df = df_scores[
    (df_scores["–í–æ—Ä–æ–Ω–∫–∞"].isin(selected_funnels)) &
    (df_scores["–ú–µ–Ω–µ–¥–∂–µ—Ä"].isin(selected_managers))
].copy()
if view_df.empty:
    st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º.")
    st.stop()

# ============ HEADER ============
st.markdown("# üüß –ë–£–†–ú–ê–® ¬∑ CRM –î—ç—à–±–æ—Ä–¥ v4.2")
st.markdown(f"**–ü–µ—Ä–∏–æ–¥**: {date_from} ‚Üí {date_to} | **–°–¥–µ–ª–æ–∫**: {len(view_df)}")

# ============ TABS ============
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "üìä –û–±–∑–æ—Ä",
    "‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã",
    "üë§ –ü–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º",
    "üéØ –ì—Ä–∞–¥–∞—Ü–∏—è —Å–¥–µ–ª–æ–∫",
    "‚è±Ô∏è –í—Ä–µ–º—è –Ω–∞ —ç—Ç–∞–ø–∞—Ö",
    "ü§ñ AI-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞"
])

# ===== TAB 1: OVERVIEW =====
with tab1:
    st.subheader("–°—É–º–º–∞—Ä–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("–°–¥–µ–ª–æ–∫", len(view_df))
    c2.metric("–í—ã—Ä—É—á–∫–∞, ‚ÇΩ", f"{int(view_df['–°—É–º–º–∞'].sum()):,}")
    c3.metric("–°—Ä. –∑–¥–æ—Ä–æ–≤—å–µ", f"{int(view_df['–ó–¥–æ—Ä–æ–≤—å–µ'].mean())}%")
    c4.metric("–°—Ä. –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª", f"{int(view_df['–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª'].mean())}%")
    st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–¥–æ—Ä–æ–≤—å—è —Å–¥–µ–ª–æ–∫")
    if px:
        fig1 = px.histogram(view_df, x="–ó–¥–æ—Ä–æ–≤—å–µ", nbins=20, title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–¥–æ—Ä–æ–≤—å—è",
                            labels={"–ó–¥–æ—Ä–æ–≤—å–µ":"–ó–¥–æ—Ä–æ–≤—å–µ (%)"}, color_discrete_sequence=["#FF6B35"])
        st.plotly_chart(fig1, use_container_width=True)
    st.subheader("–¢–æ–ø-5 —ç—Ç–∞–ø–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–¥–µ–ª–æ–∫")
    if px:
        stage_counts = (view_df.groupby("–ù–∞–∑–≤–∞–Ω–∏–µ —ç—Ç–∞–ø–∞").size()
                        .reset_index(name="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
                        .sort_values("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", ascending=False).head(5))
        fig2 = px.bar(stage_counts, x="–ù–∞–∑–≤–∞–Ω–∏–µ —ç—Ç–∞–ø–∞", y="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ",
                      title="–¢–æ–ø-5 —ç—Ç–∞–ø–æ–≤", color="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", color_continuous_scale="Oranges")
        st.plotly_chart(fig2, use_container_width=True)
    st.subheader("–í—ã—Ä—É—á–∫–∞ –ø–æ –≤–æ—Ä–æ–Ω–∫–∞–º")
    if px:
        funnel_rev = view_df.groupby("–í–æ—Ä–æ–Ω–∫–∞")["–°—É–º–º–∞"].sum().reset_index()
        fig3 = px.pie(funnel_rev, names="–í–æ—Ä–æ–Ω–∫–∞", values="–°—É–º–º–∞", title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—ã—Ä—É—á–∫–∏")
        st.plotly_chart(fig3, use_container_width=True)

# ===== TAB 2: PROBLEMS =====
with tab2:
    st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–±–ª–µ–º")
    no_tasks   = view_df[view_df["–ù–µ—Ç –∑–∞–¥–∞—á"]]
    no_company = view_df[view_df["–ù–µ—Ç –∫–æ–º–ø–∞–Ω–∏–∏"]]
    no_contact = view_df[view_df["–ù–µ—Ç –∫–æ–Ω—Ç–∞–∫—Ç–∞"]]
    stuck      = view_df[view_df["–ó–∞—Å—Ç—Ä—è–ª–∞"]]
    lost       = view_df[view_df["–ü—Ä–æ–∏–≥—Ä–∞–Ω–∞"]]
    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("–ë–µ–∑ –∑–∞–¥–∞—á", len(no_tasks), f"{len(no_tasks)/len(view_df)*100:.1f}%")
    c2.metric("–ë–µ–∑ –∫–æ–º–ø–∞–Ω–∏–∏", len(no_company), f"{len(no_company)/len(view_df)*100:.1f}%")
    c3.metric("–ë–µ–∑ –∫–æ–Ω—Ç–∞–∫—Ç–∞", len(no_contact), f"{len(no_contact)/len(view_df)*100:.1f}%")
    c4.metric("–ó–∞—Å—Ç—Ä—è–ª–∏", len(stuck), f"{len(stuck)/len(view_df)*100:.1f}%")
    c5.metric("–ü—Ä–æ–∏–≥—Ä–∞–Ω—ã", len(lost), f"{len(lost)/len(view_df)*100:.1f}%")
    if px:
        problem_counts = pd.DataFrame({
            "–ü—Ä–æ–±–ª–µ–º–∞":["–ë–µ–∑ –∑–∞–¥–∞—á","–ë–µ–∑ –∫–æ–º–ø–∞–Ω–∏–∏","–ë–µ–∑ –∫–æ–Ω—Ç–∞–∫—Ç–∞","–ó–∞—Å—Ç—Ä—è–ª–∏","–ü—Ä–æ–∏–≥—Ä–∞–Ω—ã"],
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ":[len(no_tasks),len(no_company),len(no_contact),len(stuck),len(lost)]
        })
        fig_prob = px.bar(problem_counts, x="–ü—Ä–æ–±–ª–µ–º–∞", y="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ",
                          title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º",
                          color="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", color_continuous_scale="Reds")
        st.plotly_chart(fig_prob, use_container_width=True)
    with st.expander(f"‚ùó –°–¥–µ–ª–∫–∏ –±–µ–∑ –∑–∞–¥–∞—á ({len(no_tasks)})"):
        if not no_tasks.empty:
            st.dataframe(no_tasks[["ID —Å–¥–µ–ª–∫–∏","–ù–∞–∑–≤–∞–Ω–∏–µ","–ú–µ–Ω–µ–¥–∂–µ—Ä","–°—É–º–º–∞","–ó–¥–æ—Ä–æ–≤—å–µ"]],
                         use_container_width=True)
    with st.expander(f"üè¢ –°–¥–µ–ª–∫–∏ –±–µ–∑ –∫–æ–º–ø–∞–Ω–∏–∏ ({len(no_company)})"):
        if not no_company.empty:
            st.dataframe(no_company[["ID —Å–¥–µ–ª–∫–∏","–ù–∞–∑–≤–∞–Ω–∏–µ","–ú–µ–Ω–µ–¥–∂–µ—Ä","–°—É–º–º–∞","–ó–¥–æ—Ä–æ–≤—å–µ"]],
                         use_container_width=True)
    with st.expander(f"üìá –°–¥–µ–ª–∫–∏ –±–µ–∑ –∫–æ–Ω—Ç–∞–∫—Ç–∞ ({len(no_contact)})"):
        if not no_contact.empty:
            st.dataframe(no_contact[["ID —Å–¥–µ–ª–∫–∏","–ù–∞–∑–≤–∞–Ω–∏–µ","–ú–µ–Ω–µ–¥–∂–µ—Ä","–°—É–º–º–∞","–ó–¥–æ—Ä–æ–≤—å–µ"]],
                         use_container_width=True)
    with st.expander(f"‚è∏Ô∏è –ó–∞—Å—Ç—Ä—è–≤—à–∏–µ —Å–¥–µ–ª–∫–∏ ({len(stuck)})"):
        if not stuck.empty:
            st.dataframe(stuck[["ID —Å–¥–µ–ª–∫–∏","–ù–∞–∑–≤–∞–Ω–∏–µ","–ú–µ–Ω–µ–¥–∂–µ—Ä","–î–Ω–µ–π –±–µ–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏","–ó–¥–æ—Ä–æ–≤—å–µ"]],
                         use_container_width=True)
    with st.expander(f"‚ùå –ü—Ä–æ–∏–≥—Ä–∞–Ω–Ω—ã–µ —Å–¥–µ–ª–∫–∏ ({len(lost)})"):
        if not lost.empty:
            st.dataframe(lost[["ID —Å–¥–µ–ª–∫–∏","–ù–∞–∑–≤–∞–Ω–∏–µ","–ú–µ–Ω–µ–¥–∂–µ—Ä","–°—É–º–º–∞","–ù–∞–∑–≤–∞–Ω–∏–µ —ç—Ç–∞–ø–∞"]],
                         use_container_width=True)

# ===== TAB 3: BY MANAGER =====
with tab3:
    st.subheader("–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º")
    mgr_stats = []
    for mgr in selected_managers:
        mg = view_df[view_df["–ú–µ–Ω–µ–¥–∂–µ—Ä"]==mgr]
        if mg.empty: continue
        total     = len(mg)
        revenue   = mg["–°—É–º–º–∞"].sum()
        avg_health= mg["–ó–¥–æ—Ä–æ–≤—å–µ"].mean()
        won       = len(mg[mg["–≠—Ç–∞–ø ID"].astype(str).str.contains("WON", case=False)])
        lost_cnt  = len(mg[mg["–ü—Ä–æ–∏–≥—Ä–∞–Ω–∞"]])
        conv_rate = (won/total*100) if total>0 else 0
        base_quality=100 - (mg["–ù–µ—Ç –∫–æ–º–ø–∞–Ω–∏–∏"].sum()+mg["–ù–µ—Ç –∫–æ–Ω—Ç–∞–∫—Ç–∞"].sum())/(total*2)*100
        mgr_stats.append({
            "–ú–µ–Ω–µ–¥–∂–µ—Ä":mgr,
            "–°–¥–µ–ª–æ–∫":total,
            "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ":int(revenue),
            "–°—Ä. –∑–¥–æ—Ä–æ–≤—å–µ, %":int(avg_health),
            "–ö–æ–Ω–≤–µ—Ä—Å–∏—è –≤ WON, %":round(conv_rate,1),
            "–ö–∞—á–µ—Å—Ç–≤–æ –±–∞–∑—ã, %":round(base_quality,1),
            "–í—ã–∏–≥—Ä–∞–Ω–æ":won,
            "–ü—Ä–æ–∏–≥—Ä–∞–Ω–æ":lost_cnt
        })
    df_mgr = pd.DataFrame(mgr_stats)
    st.dataframe(df_mgr, use_container_width=True)
    if px and not df_mgr.empty:
        st.subheader("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º")
        fig4 = px.bar(df_mgr, x="–ú–µ–Ω–µ–¥–∂–µ—Ä", y="–í—ã—Ä—É—á–∫–∞, ‚ÇΩ",
                      title="–í—ã—Ä—É—á–∫–∞ –ø–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º",
                      color="–°—Ä. –∑–¥–æ—Ä–æ–≤—å–µ, %", color_continuous_scale="RdYlGn")
        st.plotly_chart(fig4, use_container_width=True)
        fig5 = px.scatter(df_mgr, x="–°–¥–µ–ª–æ–∫", y="–ö–æ–Ω–≤–µ—Ä—Å–∏—è –≤ WON, %",
                          size="–í—ã—Ä—É—á–∫–∞, ‚ÇΩ", hover_data=["–ú–µ–Ω–µ–¥–∂–µ—Ä"],
                          title="–°–¥–µ–ª–∫–∏ vs –ö–æ–Ω–≤–µ—Ä—Å–∏—è")
        st.plotly_chart(fig5, use_container_width=True)
    st.subheader("–ö–æ–Ω–≤–µ—Ä—Å–∏—è –ø–æ —ç—Ç–∞–ø–∞–º –≤–æ—Ä–æ–Ω–∫–∏")
    conv_data = compute_conversion_by_manager_and_funnel(view_df, sort_map)
    for _, row in conv_data.iterrows():
        with st.expander(f"üë§ {row['–ú–µ–Ω–µ–¥–∂–µ—Ä']} | {row['–í–æ—Ä–æ–Ω–∫–∞']} ({row['–í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫']} —Å–¥–µ–ª–æ–∫)"):
            stage_df = pd.DataFrame(row['–≠—Ç–∞–ø—ã'])
            st.dataframe(stage_df, use_container_width=True)
            if px and not stage_df.empty:
                fig6 = px.funnel(stage_df, x="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", y="–≠—Ç–∞–ø",
                                 title="–í–æ—Ä–æ–Ω–∫–∞ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏")
                st.plotly_chart(fig6, use_container_width=True)

# ===== TAB 4: DEAL GRADATION =====
with tab4:
    st.subheader("–ì—Ä–∞–¥–∞—Ü–∏—è —Å–¥–µ–ª–æ–∫ –ø–æ –∑–¥–æ—Ä–æ–≤—å—é")
    quick = view_df[view_df["–ë—ã—Å—Ç—Ä–∞—è –ø–æ–±–µ–¥–∞?"]].sort_values("–°–∫–æ—Ä –±—ã—Å—Ç—Ä–æ–π –ø–æ–±–µ–¥—ã", ascending=False)
    work  = view_df[(~view_df["–ë—ã—Å—Ç—Ä–∞—è –ø–æ–±–µ–¥–∞?"]) & (~view_df["–°—Ç–æ–ø-–ª–∏—Å—Ç?"])].sort_values("–ó–¥–æ—Ä–æ–≤—å–µ", ascending=False)
    drop  = view_df[view_df["–°—Ç–æ–ø-–ª–∏—Å—Ç?"]].sort_values("–°–∫–æ—Ä –æ—Ç–∫–∞–∑–∞", ascending=False)
    c1, c2, c3 = st.columns(3)
    c1.metric("üü¢ Quick Wins", len(quick), f"{int(quick['–°—É–º–º–∞'].sum()):,} ‚ÇΩ")
    c2.metric("üü° –ü—Ä–æ—Ä–∞–±–æ—Ç–∫–∞", len(work), f"{int(work['–°—É–º–º–∞'].sum()):,} ‚ÇΩ")
    c3.metric("üî¥ Stop List", len(drop), f"{int(drop['–°—É–º–º–∞'].sum()):,} ‚ÇΩ")
    if px:
        gradation_counts = pd.DataFrame({
            "–ö–∞—Ç–µ–≥–æ—Ä–∏—è":["Quick Wins","–ü—Ä–æ—Ä–∞–±–æ—Ç–∫–∞","Stop List"],
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ":[len(quick),len(work),len(drop)],
            "–°—É–º–º–∞":[quick['–°—É–º–º–∞'].sum(), work['–°—É–º–º–∞'].sum(), drop['–°—É–º–º–∞'].sum()]
        })
        fig7 = px.bar(gradation_counts, x="–ö–∞—Ç–µ–≥–æ—Ä–∏—è", y="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ",
                      title="–ì—Ä–∞–¥–∞—Ü–∏—è —Å–¥–µ–ª–æ–∫",
                      color="–ö–∞—Ç–µ–≥–æ—Ä–∏—è",
                      color_discrete_map={"Quick Wins":"green","–ü—Ä–æ—Ä–∞–±–æ—Ç–∫–∞":"orange","Stop List":"red"})
        st.plotly_chart(fig7, use_container_width=True)
    with st.expander(f"üü¢ Quick Wins ({len(quick)})"):
        if not quick.empty:
            st.dataframe(quick[["ID —Å–¥–µ–ª–∫–∏","–ù–∞–∑–≤–∞–Ω–∏–µ","–ú–µ–Ω–µ–¥–∂–µ—Ä","–°—É–º–º–∞","–ó–¥–æ—Ä–æ–≤—å–µ","–°–∫–æ—Ä –±—ã—Å—Ç—Ä–æ–π –ø–æ–±–µ–¥—ã","ETA –¥–Ω–µ–π"]],
                         use_container_width=True)
    with st.expander(f"üü° –ü—Ä–æ—Ä–∞–±–æ—Ç–∫–∞ ({len(work)})"):
        if not work.empty:
            st.dataframe(work[["ID —Å–¥–µ–ª–∫–∏","–ù–∞–∑–≤–∞–Ω–∏–µ","–ú–µ–Ω–µ–¥–∂–µ—Ä","–°—É–º–º–∞","–ó–¥–æ—Ä–æ–≤—å–µ","–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª"]],
                         use_container_width=True)
    with st.expander(f"üî¥ Stop List ({len(drop)})"):
        if not drop.empty:
            st.dataframe(drop[["ID —Å–¥–µ–ª–∫–∏","–ù–∞–∑–≤–∞–Ω–∏–µ","–ú–µ–Ω–µ–¥–∂–µ—Ä","–°—É–º–º–∞","–ó–¥–æ—Ä–æ–≤—å–µ","–°–∫–æ—Ä –æ—Ç–∫–∞–∑–∞","–î–Ω–µ–π –±–µ–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"]],
                         use_container_width=True)

# ===== TAB 5: TIME ON STAGES =====
with tab5:
    st.subheader("–í—Ä–µ–º—è –Ω–∞ —ç—Ç–∞–ø–∞—Ö –≤–æ—Ä–æ–Ω–∫–∏")
    stage_time = view_df.groupby("–ù–∞–∑–≤–∞–Ω–∏–µ —ç—Ç–∞–ø–∞").agg({
        "–î–Ω–µ–π –Ω–∞ —ç—Ç–∞–ø–µ":["mean","std","min","max"]
    }).round(1)
    stage_time.columns = ["–°—Ä. –¥–Ω–µ–π","–û—Ç–∫–ª. (œÉ)","–ú–∏–Ω","–ú–∞–∫—Å"]
    stage_time = stage_time.reset_index()
    st.dataframe(stage_time, use_container_width=True)
    if px and not stage_time.empty:
        fig8 = px.bar(stage_time, x="–ù–∞–∑–≤–∞–Ω–∏–µ —ç—Ç–∞–ø–∞", y="–°—Ä. –¥–Ω–µ–π",
                      error_y="–û—Ç–∫–ª. (œÉ)", title="–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —ç—Ç–∞–ø–∞—Ö",
                      color="–°—Ä. –¥–Ω–µ–π", color_continuous_scale="Blues")
        st.plotly_chart(fig8, use_container_width=True)
    st.subheader("–û—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –ø–æ —Å–¥–µ–ª–∫–∞–º")
    mean_stage_time = view_df.groupby("–≠—Ç–∞–ø ID")["–î–Ω–µ–π –Ω–∞ —ç—Ç–∞–ø–µ"].mean().to_dict()
    view_df["–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–Ω–µ–π"] = view_df.apply(
        lambda r: r["–î–Ω–µ–π –Ω–∞ —ç—Ç–∞–ø–µ"] - mean_stage_time.get(r["–≠—Ç–∞–ø ID"], 0), axis=1
    )
    outliers = view_df[abs(view_df["–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–Ω–µ–π"])>7].sort_values("–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–Ω–µ–π", ascending=False)
    st.dataframe(outliers[["ID —Å–¥–µ–ª–∫–∏","–ù–∞–∑–≤–∞–Ω–∏–µ","–ú–µ–Ω–µ–¥–∂–µ—Ä","–ù–∞–∑–≤–∞–Ω–∏–µ —ç—Ç–∞–ø–∞","–î–Ω–µ–π –Ω–∞ —ç—Ç–∞–ø–µ","–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–Ω–µ–π"]],
                 use_container_width=True)

# ===== TAB 6: AI ANALYTICS =====
with tab6:
    st.subheader("ü§ñ AI-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º")
    for mgr in selected_managers:
        mg = view_df[view_df["–ú–µ–Ω–µ–¥–∂–µ—Ä"]==mgr]
        if mg.empty: continue
        summary = {
            "total_deals": len(mg),
            "revenue": int(mg["–°—É–º–º–∞"].sum()),
            "avg_health": int(mg["–ó–¥–æ—Ä–æ–≤—å–µ"].mean()),
            "no_tasks": int(mg["–ù–µ—Ç –∑–∞–¥–∞—á"].sum()),
            "no_company": int(mg["–ù–µ—Ç –∫–æ–º–ø–∞–Ω–∏–∏"].sum()),
            "no_contact": int(mg["–ù–µ—Ç –∫–æ–Ω—Ç–∞–∫—Ç–∞"].sum()),
            "stuck": int(mg["–ó–∞—Å—Ç—Ä—è–ª–∞"].sum()),
            "lost": int(mg["–ü—Ä–æ–∏–≥—Ä–∞–Ω–∞"].sum()),
            "won": len(mg[mg["–≠—Ç–∞–ø ID"].astype(str).str.contains("WON", case=False)])
        }
        with st.expander(f"üë§ {mgr} ({len(mg)} —Å–¥–µ–ª–æ–∫)"):
            with st.spinner("–ì–µ–Ω–µ—Ä–∏—Ä—É—é AI-–∞–Ω–∞–ª–∏–∑..."):
                analysis = ai_analyze_manager(mgr, summary)
                st.markdown(analysis)

# ===== TAB 7: YEARLY PLAN =====
tab7 = st.tabs(["üéØ –ì–æ–¥–æ–≤–æ–π –ø–ª–∞–Ω"])[0]
with tab7:
    st.subheader("–ì–æ–¥–æ–≤–æ–π –ø–ª–∞–Ω –ø–æ –≤—ã—Ä—É—á–∫–µ")
    yearly_target = st.number_input("–¶–µ–ª—å –Ω–∞ –≥–æ–¥, ‚ÇΩ", min_value=0, value=10_000_000, step=100_000, format="%d")
    start_month = st.selectbox("–°—Ç–∞—Ä—Ç–æ–≤—ã–π –º–µ—Å—è—Ü –æ—Ç—á—ë—Ç–∞", list(range(1,13)), index=datetime.now().month-1)

    df_year = view_df.copy()
    df_year = df_year[df_year["–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è"].dt.year == datetime.now().year]
    df_year["–ú–µ—Å—è—Ü"] = df_year["–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è"].dt.month

    # –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –≤—ã—Ä—É—á–∫–∞ –ø–æ –º–µ—Å—è—Ü–∞–º
    actual = df_year.groupby("–ú–µ—Å—è—Ü")["–°—É–º–º–∞"].sum().reindex(range(1,13), fill_value=0)
    months = list(range(start_month, start_month+12))
    months = [((m-1)%12)+1 for m in months]

    # –û—Å—Ç–∞–≤—à–∏–µ—Å—è –º–µ—Å—è—Ü—ã
    current_month = datetime.now().month
    months_left = [m for m in months if m >= current_month]
    revenue_to_go = yearly_target - actual.sum()
    monthly_plan = {m: max(0, revenue_to_go / len(months_left)) for m in months_left}

    # –°–æ–±–∏—Ä–∞–µ–º DataFrame
    plan_df = pd.DataFrame({
        "–ú–µ—Å—è—Ü": months,
        "–§–∞–∫—Ç, ‚ÇΩ": [actual.get(m,0) for m in months],
        "–ü–ª–∞–Ω, ‚ÇΩ": [monthly_plan.get(m,0) if m in monthly_plan else None for m in months]
    })
    plan_df["–ü–ª–∞–Ω, ‚ÇΩ"] = plan_df["–ü–ª–∞–Ω, ‚ÇΩ"].ffill().bfill()

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    if px:
        fig_plan = px.area(
            plan_df,
            x="–ú–µ—Å—è—Ü",
            y=["–§–∞–∫—Ç, ‚ÇΩ","–ü–ª–∞–Ω, ‚ÇΩ"],
            labels={"value":"–°—É–º–º–∞, ‚ÇΩ","–ú–µ—Å—è—Ü":"–ú–µ—Å—è—Ü"},
            title="–§–∞–∫—Ç vs –ü–ª–∞–Ω –ø–æ –º–µ—Å—è—Ü–∞–º",
            color_discrete_map={"–§–∞–∫—Ç, ‚ÇΩ":"#2E91E5","–ü–ª–∞–Ω, ‚ÇΩ":"#E15F99"}
        )
        st.plotly_chart(fig_plan, use_container_width=True)

    st.subheader("–¢–∞–±–ª–∏—Ü–∞ –ø–ª–∞–Ω–∞ –∏ —Ñ–∞–∫—Ç–∞")
    st.dataframe(
        plan_df.assign(**{"–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ, ‚ÇΩ": plan_df["–§–∞–∫—Ç, ‚ÇΩ"] - plan_df["–ü–ª–∞–Ω, ‚ÇΩ"]})
               .round(0),
        use_container_width=True
    )

st.markdown("---")
st.caption("–ë–£–†–ú–ê–® ¬∑ CRM –î—ç—à–±–æ—Ä–¥ v4.2 | Powered by Bitrix24 + Perplexity AI")
